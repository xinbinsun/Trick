{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4avF0jJ8xTsy",
        "JSWpnonXIrYg"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinbinsun/Trick/blob/main/cuda/1_introduction_to_parallel_programming_and_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 一、并行编程导论与CUDA入门\n",
        "\n",
        "博客文章：\n",
        "\n",
        "- [《一、并行编程导论与CUDA入门》](https://jasonkayzk.github.io/2025/07/25/一、并行编程导论与CUDA入门/)"
      ],
      "metadata": {
        "id": "7m5yJkRCw7Eg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CPU加法案例"
      ],
      "metadata": {
        "id": "4avF0jJ8xTsy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "br-0bp1n6KG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3235a7-800d-4070-c412-5643f153dc6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add_cpu.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile add_cpu.cpp\n",
        "\n",
        "#include <cmath>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "// Step 2: Define add function\n",
        "void add_cpu(std::vector<float> &c, const std::vector<float> &a, const std::vector<float> &b) {\n",
        "    // CPU use loop to calculate\n",
        "    for (size_t i = 0; i < a.size(); i++) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Step 1: Prepare & initialize data\n",
        "    constexpr size_t N = 1 << 20; // ~1M elements\n",
        "\n",
        "    // Initialize data\n",
        "    const std::vector<float> a(N, 1);\n",
        "    const std::vector<float> b(N, 2);\n",
        "    std::vector<float> c(N, 0);\n",
        "\n",
        "    // Step 3: Call the cpu addition function\n",
        "    add_cpu(c, a, b);\n",
        "\n",
        "    // Step 4: Check for errors (all values should be 3.0f)\n",
        "    float maxError = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        maxError = fmax(maxError, fabs(c[i] - 3.0f));\n",
        "    }\n",
        "    std::cout << \"Max error: \" << maxError << std::endl;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "g++ add_cpu.cpp -o add_cpu\n",
        "\n",
        "./add_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXrj8XoDxZLE",
        "outputId": "bc2a07e4-1a85-49cf-d048-175726d026b9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max error: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA加法案例"
      ],
      "metadata": {
        "id": "JSWpnonXIrYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add_cuda.cu\n",
        "\n",
        "#include <cmath>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "\n",
        "#define CUDA_CHECK(call) \\\n",
        "{ \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        std::cerr << \"CUDA Error at \" << __FILE__ << \":\" << __LINE__ \\\n",
        "        << \" - \" << cudaGetErrorString(err) << std::endl; \\\n",
        "    } \\\n",
        "}\n",
        "\n",
        "// Step 3: Define add kernel\n",
        "/**\n",
        " * @brief CUDA kernel for element-wise addition: c = a+b\n",
        " * @tparam T The data type of the arrays, which can be any type that supports addition operations(e.g.. int, float)\n",
        " *\n",
        " * @param c Pointer to the result array, where the results of the addition are stored.\n",
        " * @param a Pointer to the first input array.\n",
        " * @param b Pointer to the second input array.\n",
        " * @param n The number of elements in the arrays. The arrays are assumed to be of equal length.\n",
        "*/\n",
        "template<typename T>\n",
        "__global__ void add_kernel(T *c, const T *a, const T *b, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Step 1: Prepare & initialize data\n",
        "    constexpr size_t N = 1 << 20; // ~1M elements\n",
        "    constexpr size_t size_bytes = sizeof(float) * N;\n",
        "\n",
        "    // Initialize data\n",
        "    const std::vector<float> h_a(N, 1);\n",
        "    const std::vector<float> h_b(N, 2);\n",
        "    std::vector<float> h_c(N, 0);\n",
        "\n",
        "    // Step 2: Allocate device memory & transfer to global memory\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    CUDA_CHECK(cudaMalloc(&d_a, size_bytes));\n",
        "    CUDA_CHECK(cudaMalloc(&d_b, size_bytes));\n",
        "    CUDA_CHECK(cudaMalloc(&d_c, size_bytes));\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(d_a, h_a.data(), size_bytes, cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_b, h_b.data(), size_bytes, cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_c, h_c.data(), size_bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Step 4: Call the cpu addition function\n",
        "    // Set up kernel configuration\n",
        "    dim3 block_dim(256);\n",
        "    dim3 grid_dim((N + block_dim.x - 1) / block_dim.x);\n",
        "\n",
        "    // Call cuda add kernel\n",
        "    add_kernel<<<grid_dim, block_dim>>>(d_c, d_a, d_b, N);\n",
        "\n",
        "    // Step 5: Transfer data from global mem to host mem\n",
        "    CUDA_CHECK(cudaMemcpy(h_c.data(), d_c, size_bytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Step 6: Check for errors (all values should be 3.0f)\n",
        "    float maxError = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        maxError = fmax(maxError, fabs(h_c[i] - 3.0f));\n",
        "    }\n",
        "    std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "    if (d_a) {\n",
        "        CUDA_CHECK(cudaFree(d_a));\n",
        "    }\n",
        "    if (d_b) {\n",
        "        CUDA_CHECK(cudaFree(d_b));\n",
        "    }\n",
        "    if (d_c) {\n",
        "        CUDA_CHECK(cudaFree(d_c));\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZZTESxpJc0H",
        "outputId": "bae55471-13bb-4deb-c804-d0a435821277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting add_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvcc add_cuda.cu -o add_cuda\n",
        "\n",
        "./add_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IknEpW0_JkIE",
        "outputId": "0b4433f1-cc1d-48ee-da03-5ae6b278ec08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max error: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用nsys进行性能分析"
      ],
      "metadata": {
        "id": "UX-JKSbtMSzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add_cuda_profiling.cu\n",
        "\n",
        "#include <cmath>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "\n",
        "#define CUDA_CHECK(call) \\\n",
        "{ \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        std::cerr << \"CUDA Error at \" << __FILE__ << \":\" << __LINE__ \\\n",
        "        << \" - \" << cudaGetErrorString(err) << std::endl; \\\n",
        "    } \\\n",
        "}\n",
        "\n",
        "// Step 3: Define add kernel\n",
        "/**\n",
        " * @brief CUDA kernel for element-wise addition: c = a+b\n",
        " * @tparam T The data type of the arrays, which can be any type that supports addition operations(e.g.. int, float)\n",
        " *\n",
        " * @param c Pointer to the result array, where the results of the addition are stored.\n",
        " * @param a Pointer to the first input array.\n",
        " * @param b Pointer to the second input array.\n",
        " * @param n The number of elements in the arrays. The arrays are assumed to be of equal length.\n",
        "*/\n",
        "template<typename T>\n",
        "__global__ void add_kernel(T *c, const T *a, const T *b, const size_t n, const size_t step) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x + step;\n",
        "    if (idx < n) {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void vector_add(T *c, const T *a, const T *b, size_t n, const dim3& grid_dim, const dim3& block_dim) {\n",
        "    size_t step = grid_dim.x * block_dim.x;\n",
        "    for (size_t i = 0; i < n; i += step) {\n",
        "        add_kernel<<<grid_dim, block_dim>>>(c, a, b, n, i);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Step 1: Prepare & initialize data\n",
        "    constexpr size_t N = 1 << 20; // ~1M elements\n",
        "    constexpr size_t size_bytes = sizeof(float) * N;\n",
        "\n",
        "    // Initialize data\n",
        "    const std::vector<float> h_a(N, 1);\n",
        "    const std::vector<float> h_b(N, 2);\n",
        "    std::vector<float> h_c(N, 0);\n",
        "\n",
        "    // Step 2: Allocate device memory & transfer to global memory\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    CUDA_CHECK(cudaMalloc(&d_a, size_bytes));\n",
        "    CUDA_CHECK(cudaMalloc(&d_b, size_bytes));\n",
        "    CUDA_CHECK(cudaMalloc(&d_c, size_bytes));\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(d_a, h_a.data(), size_bytes, cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_b, h_b.data(), size_bytes, cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_c, h_c.data(), size_bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Step 4: Call the cpu addition function\n",
        "    // Set up kernel configuration\n",
        "    dim3 block_dim(1);\n",
        "    dim3 grid_dim(1);\n",
        "\n",
        "    // Call cuda add kernel\n",
        "    vector_add(d_c, d_a, d_b, N, block_dim, grid_dim);\n",
        "\n",
        "    // Step 5: Transfer data from global mem to host mem\n",
        "    CUDA_CHECK(cudaMemcpy(h_c.data(), d_c, size_bytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Step 6: Check for errors (all values should be 3.0f)\n",
        "    float sumError = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        sumError += fabs(h_c[i] - 3.0f);\n",
        "    }\n",
        "    std::cout << \"Sum error: \" << sumError << std::endl;\n",
        "\n",
        "    if (d_a) {\n",
        "        CUDA_CHECK(cudaFree(d_a));\n",
        "    }\n",
        "    if (d_b) {\n",
        "        CUDA_CHECK(cudaFree(d_b));\n",
        "    }\n",
        "    if (d_c) {\n",
        "        CUDA_CHECK(cudaFree(d_c));\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S139fnFvR4Pv",
        "outputId": "c960d645-4016-410e-d482-24d77a04f710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting add_cuda_profiling.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvcc add_cuda_profiling.cu -o add_cuda_profiling && ./add_cuda_profiling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa7bw6oVT8JX",
        "outputId": "4ca16de3-4f18-48f4-97f5-814c5b104912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum error: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%shell\n",
        "\n",
        "# Download and install CUDA 12.1\n",
        "! set -x \\\n",
        "&& cd $(mktemp -d) \\\n",
        "&& wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run \\\n",
        "&& sudo sh cuda_12.1.0_530.30.02_linux.run --silent --toolkit \\\n",
        "&& rm cuda_12.1.0_530.30.02_linux.run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV9rtnNuOCOG",
        "outputId": "2b2a0aa3-89d5-4750-a31b-a1bfee0552d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++ mktemp -d\n",
            "+ cd /tmp/tmp.SuB2rbewF0\n",
            "+ wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run\n",
            "--2025-07-29 08:08:20--  https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 23.59.88.14, 23.59.88.2\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|23.59.88.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4245586997 (4.0G) [application/octet-stream]\n",
            "Saving to: ‘cuda_12.1.0_530.30.02_linux.run’\n",
            "\n",
            "cuda_12.1.0_530.30. 100%[===================>]   3.95G  64.8MB/s    in 59s     \n",
            "\n",
            "2025-07-29 08:09:19 (68.4 MB/s) - ‘cuda_12.1.0_530.30.02_linux.run’ saved [4245586997/4245586997]\n",
            "\n",
            "+ sudo sh cuda_12.1.0_530.30.02_linux.run --silent --toolkit\n",
            "+ rm cuda_12.1.0_530.30.02_linux.run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Add CUDA installation to PATH\n",
        "os.environ['PATH'] = os.environ['PATH'] + ':/usr/local/cuda/bin/'"
      ],
      "metadata": {
        "id": "9pdhKNyRORmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%shell\n",
        "\n",
        "# Run Nsight command-line utility\n",
        "! nsys --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekDOayhTOSli",
        "outputId": "6ea4c3bf-95ab-4f9d-d6ea-3752d1f44911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA Nsight Systems version 2023.1.2.43-32377213v0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%shell\n",
        "\n",
        "# 启动 profiling\n",
        "! nsys profile -t cuda,nvtx,osrt -o add_cuda_profiling -f true ./add_cuda_profiling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bSFSjh_MW0v",
        "outputId": "fa7089fe-f56c-4d95-e352-efabb61f6531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum error: 0\n",
            "Generating '/tmp/nsys-report-84cb.qdstrm'\n",
            "[1/1] [========================100%] add_cuda_profiling.nsys-rep\n",
            "Generated:\n",
            "    /content/add_cuda_profiling.nsys-rep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%shell\n",
        "\n",
        "# 解析并统计性能信息：\n",
        "! nsys stats add_cuda_profiling.nsys-rep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYQUBwOCQcL9",
        "outputId": "f69e8235-60a8-4ebc-fad2-7b7185759a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating SQLite file add_cuda_profiling.sqlite from add_cuda_profiling.nsys-rep\n",
            "Exporting 2215683 events: [================================================100%]\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/nvtx_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/osrt_sum.py]... \n",
            "\n",
            " ** OS Runtime Summary (osrt_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)      Min (ns)    Max (ns)     StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  -------------  -------------  ----------  -----------  -------------  ----------------------\n",
            "     56.2    7,592,724,284         84   90,389,574.8  100,130,776.0       2,330  370,626,986   45,049,255.4  poll                  \n",
            "     42.4    5,736,493,727         26  220,634,374.1  189,702,756.5  41,077,614  752,975,386  124,762,585.8  sem_wait              \n",
            "      1.2      164,252,099        543      302,490.1       13,509.0         529  111,402,991    4,818,716.4  ioctl                 \n",
            "      0.1       14,968,499         38      393,907.9      131,267.0         135    5,539,804      890,642.6  pthread_rwlock_wrlock \n",
            "      0.0        6,061,971          2    3,030,985.5    3,030,985.5       4,735    6,057,236    4,279,764.5  pthread_cond_broadcast\n",
            "      0.0        2,114,303         31       68,203.3       13,147.0      10,574    1,391,041      246,225.8  mmap64                \n",
            "      0.0          475,202          7       67,886.0       60,655.0      47,498      110,595       21,582.2  sem_timedwait         \n",
            "      0.0          411,287         49        8,393.6        7,537.0       3,416       22,812        3,559.3  open64                \n",
            "      0.0          315,696          4       78,924.0        3,745.0         307      307,899      152,658.7  fwrite                \n",
            "      0.0          302,691         49        6,177.4        4,006.0       1,063       32,553        6,233.0  fopen                 \n",
            "      0.0          282,976          4       70,744.0       69,367.5      50,841       93,400       19,500.1  pthread_create        \n",
            "      0.0          210,812         15       14,054.1        6,679.0       2,562       86,661       20,913.1  mmap                  \n",
            "      0.0          120,836          1      120,836.0      120,836.0     120,836      120,836            0.0  pthread_cond_wait     \n",
            "      0.0           92,413         12        7,701.1        7,052.5       1,040       13,131        3,319.8  write                 \n",
            "      0.0           81,576         41        1,989.7        1,628.0         907        8,058        1,401.5  fclose                \n",
            "      0.0           76,961         46        1,673.1           78.5          45       35,739        6,132.6  fgets                 \n",
            "      0.0           70,339          1       70,339.0       70,339.0      70,339       70,339            0.0  putc                  \n",
            "      0.0           41,884         66          634.6          547.5         180        5,018          601.3  fcntl                 \n",
            "      0.0           38,976          5        7,795.2        7,750.0       6,772        9,659        1,175.7  munmap                \n",
            "      0.0           33,816          6        5,636.0        5,068.0       1,764        9,625        3,136.0  open                  \n",
            "      0.0           29,177         16        1,823.6        1,599.0         557        3,762        1,001.3  read                  \n",
            "      0.0           19,311          2        9,655.5        9,655.5       7,523       11,788        3,015.8  socket                \n",
            "      0.0           18,067          3        6,022.3        6,490.0       3,380        8,197        2,442.3  pipe2                 \n",
            "      0.0           10,327          1       10,327.0       10,327.0      10,327       10,327            0.0  connect               \n",
            "      0.0           10,111          5        2,022.2        1,091.0         120        4,689        2,130.7  fread                 \n",
            "      0.0            8,267          1        8,267.0        8,267.0       8,267        8,267            0.0  fopen64               \n",
            "      0.0            3,036          8          379.5          365.0         311          462           54.5  dup                   \n",
            "      0.0            1,877         17          110.4           39.0          35          727          189.2  fflush                \n",
            "      0.0            1,464          1        1,464.0        1,464.0       1,464        1,464            0.0  bind                  \n",
            "      0.0            1,304          1        1,304.0        1,304.0       1,304        1,304            0.0  listen                \n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_api_sum.py]... \n",
            "\n",
            " ** CUDA API Summary (cuda_api_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)     Med (ns)    Min (ns)   Max (ns)     StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  -----------  --------  -----------  -------------  ----------------------\n",
            "     96.9    6,504,565,162  1,048,576       6,203.2      5,159.0     2,928   37,814,020       99,097.6  cudaLaunchKernel      \n",
            "      3.0      203,141,797          3  67,713,932.3    103,908.0    73,162  202,964,727  117,130,625.1  cudaMalloc            \n",
            "      0.1        4,017,591          4   1,004,397.8  1,012,632.0   941,545    1,050,782       45,652.8  cudaMemcpy            \n",
            "      0.0          524,788          3     174,929.3    136,182.0   122,785      265,821       78,999.0  cudaFree              \n",
            "      0.0            2,584          1       2,584.0      2,584.0     2,584        2,584            0.0  cuModuleGetLoadingMode\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_gpu_kern_sum.py]... \n",
            "\n",
            " ** CUDA GPU Kernel Summary (cuda_gpu_kern_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)                                         Name                                       \n",
            " --------  ---------------  ---------  --------  --------  --------  --------  -----------  ----------------------------------------------------------------------------------\n",
            "    100.0    1,531,278,261  1,048,576   1,460.3   1,280.0     1,215     3,744        398.0  void add_kernel<float>(T1 *, const T1 *, const T1 *, unsigned long, unsigned long)\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_gpu_mem_time_sum.py]... \n",
            "\n",
            " ** CUDA GPU MemOps Summary (by Time) (cuda_gpu_mem_time_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)      Operation     \n",
            " --------  ---------------  -----  ---------  ---------  --------  --------  -----------  ------------------\n",
            "     78.5        2,315,208      3  771,736.0  771,064.0   767,288   776,856      4,819.3  [CUDA memcpy HtoD]\n",
            "     21.5          632,377      1  632,377.0  632,377.0   632,377   632,377          0.0  [CUDA memcpy DtoH]\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_gpu_mem_size_sum.py]... \n",
            "\n",
            " ** CUDA GPU MemOps Summary (by Size) (cuda_gpu_mem_size_sum):\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ------------------\n",
            "     12.583      3     4.194     4.194     4.194     4.194        0.000  [CUDA memcpy HtoD]\n",
            "      4.194      1     4.194     4.194     4.194     4.194        0.000  [CUDA memcpy DtoH]\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/openmp_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain OpenMP event data.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/opengl_khr_range_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain KHR Extension (KHR_DEBUG) data.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/opengl_khr_gpu_range_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain GPU KHR Extension (KHR_DEBUG) data.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/vulkan_marker_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain Vulkan Debug Extension (Vulkan Debug Util) data.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/vulkan_gpu_marker_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain GPU Vulkan Debug Extension (GPU Vulkan Debug markers) data.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/dx11_pix_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain DX11 CPU debug markers.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/dx12_gpu_marker_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain DX12 GPU debug markers.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/dx12_pix_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain DX12 CPU debug markers.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/wddm_queue_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain WDDM context data.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/um_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain CUDA Unified Memory CPU page faults data.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/um_total_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain CUDA Unified Memory CPU page faults data.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/um_cpu_page_faults_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain CUDA Unified Memory CPU page faults data.\n",
            "\n",
            "Processing [add_cuda_profiling.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/openacc_sum.py]... \n",
            "SKIPPED: add_cuda_profiling.sqlite does not contain OpenACC event data.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 将循环放入核函数（Grid-strided loop）优化"
      ],
      "metadata": {
        "id": "pg3CaxkPZANc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add_cuda_profiling2.cu\n",
        "\n",
        "#include <cmath>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "\n",
        "#define CUDA_CHECK(call) \\\n",
        "{ \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        std::cerr << \"CUDA Error at \" << __FILE__ << \":\" << __LINE__ \\\n",
        "        << \" - \" << cudaGetErrorString(err) << std::endl; \\\n",
        "    } \\\n",
        "}\n",
        "\n",
        "// Step 3: Define add kernel\n",
        "template<typename T>\n",
        "__global__ void add_kernel_inner_loop(T *c, const T *a, const T *b, const size_t n, const size_t step) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    for (size_t i = idx; i < n; i += step) {\n",
        "        if (i < n) {\n",
        "            c[i] = a[i] + b[i];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void vector_add(T *c, const T *a, const T *b, size_t n, const dim3& grid_dim, const dim3& block_dim) {\n",
        "    size_t step = grid_dim.x * block_dim.x;\n",
        "    add_kernel_inner_loop<<<grid_dim, block_dim>>>(c, a, b, n, step);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Step 1: Prepare & initialize data\n",
        "    constexpr size_t N = 1 << 20; // ~1M elements\n",
        "    constexpr size_t size_bytes = sizeof(float) * N;\n",
        "\n",
        "    // Initialize data\n",
        "    const std::vector<float> h_a(N, 1);\n",
        "    const std::vector<float> h_b(N, 2);\n",
        "    std::vector<float> h_c(N, 0);\n",
        "\n",
        "    // Step 2: Allocate device memory & transfer to global memory\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    CUDA_CHECK(cudaMalloc(&d_a, size_bytes));\n",
        "    CUDA_CHECK(cudaMalloc(&d_b, size_bytes));\n",
        "    CUDA_CHECK(cudaMalloc(&d_c, size_bytes));\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(d_a, h_a.data(), size_bytes, cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_b, h_b.data(), size_bytes, cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_c, h_c.data(), size_bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Step 4: Call the cpu addition function\n",
        "    // Set up kernel configuration\n",
        "    dim3 block_dim(1);\n",
        "    dim3 grid_dim(1);\n",
        "\n",
        "    // Call cuda add kernel\n",
        "    vector_add(d_c, d_a, d_b, N, block_dim, grid_dim);\n",
        "\n",
        "    // Step 5: Transfer data from global mem to host mem\n",
        "    CUDA_CHECK(cudaMemcpy(h_c.data(), d_c, size_bytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Step 6: Check for errors (all values should be 3.0f)\n",
        "    float sumError = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        sumError += fabs(h_c[i] - 3.0f);\n",
        "    }\n",
        "    std::cout << \"Sum error: \" << sumError << std::endl;\n",
        "\n",
        "    if (d_a) {\n",
        "        CUDA_CHECK(cudaFree(d_a));\n",
        "    }\n",
        "    if (d_b) {\n",
        "        CUDA_CHECK(cudaFree(d_b));\n",
        "    }\n",
        "    if (d_c) {\n",
        "        CUDA_CHECK(cudaFree(d_c));\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_GohDazZGkM",
        "outputId": "46b572af-677e-46b0-8717-30a0587e95be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting add_cuda_profiling2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvcc add_cuda_profiling2.cu -o add_cuda_profiling2 && ./add_cuda_profiling2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj3BYwhiZaj1",
        "outputId": "0fbde04a-4605-4186-c10b-44a1076f9acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum error: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%shell\n",
        "\n",
        "# 启动 profiling\n",
        "! nsys profile -t cuda,nvtx,osrt -o add_cuda_profiling2 -f true ./add_cuda_profiling2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vSCrVdgZMG3",
        "outputId": "8ede2d64-498e-41cb-86ef-9e9c73c688bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum error: 0\n",
            "Generating '/tmp/nsys-report-7872.qdstrm'\n",
            "[1/1] [========================100%] add_cuda_profiling2.nsys-rep\n",
            "Generated:\n",
            "    /content/add_cuda_profiling2.nsys-rep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%shell\n",
        "\n",
        "# 解析并统计性能信息：\n",
        "! nsys stats add_cuda_profiling2.nsys-rep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6rhpCBkZUTh",
        "outputId": "6e8f638c-dcb5-4326-af3d-bf28bd1ff600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating SQLite file add_cuda_profiling2.sqlite from add_cuda_profiling2.nsys-rep\n",
            "\rExporting 1727 events: [1%                                                     ]\rExporting 1727 events: [2%                                                     ]\rExporting 1727 events: [3%                                                     ]\rExporting 1727 events: [4%                                                     ]\rExporting 1727 events: [5%                                                     ]\rExporting 1727 events: [=6%                                                    ]\rExporting 1727 events: [=7%                                                    ]\rExporting 1727 events: [==8%                                                   ]\rExporting 1727 events: [==9%                                                   ]\rExporting 1727 events: [==10%                                                  ]\rExporting 1727 events: [===11%                                                 ]\rExporting 1727 events: [===12%                                                 ]\rExporting 1727 events: [====13%                                                ]\rExporting 1727 events: [====14%                                                ]\rExporting 1727 events: [=====15%                                               ]\rExporting 1727 events: [=====16%                                               ]\rExporting 1727 events: [======17%                                              ]\rExporting 1727 events: [======18%                                              ]\rExporting 1727 events: [=======19%                                             ]\rExporting 1727 events: [========20%                                            ]\rExporting 1727 events: [========21%                                            ]\rExporting 1727 events: [=========22%                                           ]\rExporting 1727 events: [=========23%                                           ]\rExporting 1727 events: [==========24%                                          ]\rExporting 1727 events: [==========25%                                          ]\rExporting 1727 events: [===========26%                                         ]\rExporting 1727 events: [===========27%                                         ]\rExporting 1727 events: [============28%                                        ]\rExporting 1727 events: [============29%                                        ]\rExporting 1727 events: [=============30%                                       ]\rExporting 1727 events: [==============31%                                      ]\rExporting 1727 events: [==============32%                                      ]\rExporting 1727 events: [===============33%                                     ]\rExporting 1727 events: [===============34%                                     ]\rExporting 1727 events: [================35%                                    ]\rExporting 1727 events: [================36%                                    ]\rExporting 1727 events: [=================37%                                   ]\rExporting 1727 events: [=================38%                                   ]\rExporting 1727 events: [==================39%                                  ]\rExporting 1727 events: [===================40%                                 ]\rExporting 1727 events: [===================41%                                 ]\rExporting 1727 events: [====================42%                                ]\rExporting 1727 events: [====================43%                                ]\rExporting 1727 events: [=====================44%                               ]\rExporting 1727 events: [=====================45%                               ]\rExporting 1727 events: [======================46%                              ]\rExporting 1727 events: [======================47%                              ]\rExporting 1727 events: [=======================48%                             ]\rExporting 1727 events: [=======================49%                             ]\rExporting 1727 events: [========================50%                            ]\rExporting 1727 events: [=========================51%                           ]\rExporting 1727 events: [=========================52%                           ]\rExporting 1727 events: [==========================53%                          ]\rExporting 1727 events: [==========================54%                          ]\rExporting 1727 events: [===========================55%                         ]\rExporting 1727 events: [===========================56%                         ]\rExporting 1727 events: [============================57%                        ]\rExporting 1727 events: [============================58%                        ]\rExporting 1727 events: [=============================59%                       ]\rExporting 1727 events: [==============================60%                      ]\rExporting 1727 events: [==============================61%                      ]\rExporting 1727 events: [===============================62%                     ]\rExporting 1727 events: [===============================63%                     ]\rExporting 1727 events: [================================64%                    ]\rExporting 1727 events: [================================65%                    ]\rExporting 1727 events: [=================================66%                   ]\rExporting 1727 events: [=================================67%                   ]\rExporting 1727 events: [==================================68%                  ]\rExporting 1727 events: [==================================69%                  ]\rExporting 1727 events: [===================================70%                 ]\rExporting 1727 events: [====================================71%                ]\rExporting 1727 events: [====================================72%                ]\rExporting 1727 events: [=====================================73%               ]\rExporting 1727 events: [=====================================74%               ]\rExporting 1727 events: [======================================75%              ]\rExporting 1727 events: [======================================76%              ]\rExporting 1727 events: [=======================================77%             ]\rExporting 1727 events: [=======================================78%             ]\rExporting 1727 events: [========================================79%            ]\rExporting 1727 events: [=========================================80%           ]\rExporting 1727 events: [=========================================81%           ]\rExporting 1727 events: [==========================================82%          ]\rExporting 1727 events: [==========================================83%          ]\rExporting 1727 events: [===========================================84%         ]\rExporting 1727 events: [===========================================85%         ]\rExporting 1727 events: [============================================86%        ]\rExporting 1727 events: [============================================87%        ]\rExporting 1727 events: [=============================================88%       ]\rExporting 1727 events: [=============================================89%       ]\rExporting 1727 events: [==============================================90%      ]\rExporting 1727 events: [===============================================91%     ]\rExporting 1727 events: [===============================================92%     ]\rExporting 1727 events: [================================================93%    ]\rExporting 1727 events: [================================================94%    ]\rExporting 1727 events: [=================================================95%   ]\rExporting 1727 events: [=================================================96%   ]\rExporting 1727 events: [==================================================97%  ]\rExporting 1727 events: [==================================================98%  ]\rExporting 1727 events: [===================================================99% ]\rExporting 1727 events: [===================================================100%]\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/nvtx_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/osrt_sum.py]... \n",
            "\n",
            " ** OS Runtime Summary (osrt_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)     Min (ns)    Max (ns)     StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  -------------  -------------  ---------  -----------  -------------  ----------------------\n",
            "     46.5      722,312,896          2  361,156,448.0  361,156,448.0  2,036,414  720,276,482  507,872,422.6  sem_wait              \n",
            "     42.1      653,139,592         15   43,542,639.5    3,367,260.0      2,468  352,813,638   92,246,979.0  poll                  \n",
            "     10.6      165,180,307        543      304,199.5       12,905.0        507  110,758,470    4,810,921.3  ioctl                 \n",
            "      0.4        6,984,109          2    3,492,054.5    3,492,054.5      2,371    6,981,738    4,935,157.7  pthread_cond_broadcast\n",
            "      0.1        2,054,391         31       66,270.7       15,815.0     10,153    1,264,922      223,296.4  mmap64                \n",
            "      0.1          875,649          9       97,294.3       66,223.0     23,669      381,882      109,115.5  sem_timedwait         \n",
            "      0.0          446,372         49        9,109.6        8,112.0      2,462       23,552        4,169.2  open64                \n",
            "      0.0          323,079         49        6,593.4        4,372.0      1,106       32,301        6,540.1  fopen                 \n",
            "      0.0          239,021          4       59,755.3       60,919.5     46,521       70,661       11,924.4  pthread_create        \n",
            "      0.0          219,161         15       14,610.7        8,837.0      2,456       93,955       22,500.6  mmap                  \n",
            "      0.0          129,687          1      129,687.0      129,687.0    129,687      129,687            0.0  pthread_cond_wait     \n",
            "      0.0           94,258         12        7,854.8        6,433.0      1,308       30,734        7,641.8  write                 \n",
            "      0.0           92,473         16        5,779.6        1,603.0        866       66,375       16,178.2  read                  \n",
            "      0.0           86,768         44        1,972.0           80.0         44       37,625        6,924.8  fgets                 \n",
            "      0.0           84,408         41        2,058.7        1,760.0        813        8,018        1,396.3  fclose                \n",
            "      0.0           42,477         66          643.6          565.5        199        5,633          658.8  fcntl                 \n",
            "      0.0           38,099          5        7,619.8        7,929.0      5,246        9,702        1,711.1  munmap                \n",
            "      0.0           37,217          6        6,202.8        5,683.5      1,734       10,426        3,012.0  open                  \n",
            "      0.0           31,321          1       31,321.0       31,321.0     31,321       31,321            0.0  putc                  \n",
            "      0.0           28,913          5        5,782.6        1,167.0         78       15,686        7,337.9  fread                 \n",
            "      0.0           21,445          3        7,148.3        7,242.0      3,619       10,584        3,483.4  pipe2                 \n",
            "      0.0           20,267          4        5,066.8        3,719.5        419       12,409        5,149.4  fwrite                \n",
            "      0.0           18,531          2        9,265.5        9,265.5      7,767       10,764        2,119.2  socket                \n",
            "      0.0            9,153          1        9,153.0        9,153.0      9,153        9,153            0.0  connect               \n",
            "      0.0            7,362          1        7,362.0        7,362.0      7,362        7,362            0.0  fopen64               \n",
            "      0.0            3,009          8          376.1          352.5        292          526           77.1  dup                   \n",
            "      0.0            1,894         17          111.4           42.0         35          674          185.2  fflush                \n",
            "      0.0            1,792          1        1,792.0        1,792.0      1,792        1,792            0.0  bind                  \n",
            "      0.0            1,062          1        1,062.0        1,062.0      1,062        1,062            0.0  listen                \n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_api_sum.py]... \n",
            "\n",
            " ** CUDA API Summary (cuda_api_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)     Med (ns)    Min (ns)   Max (ns)     StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  -----------  --------  -----------  -------------  ----------------------\n",
            "     55.4      204,935,456          3  68,311,818.7    104,741.0    79,097  204,751,618  118,160,333.0  cudaMalloc            \n",
            "     44.4      164,057,041          4  41,014,260.3  1,000,521.5   926,775  161,129,223   80,076,651.2  cudaMemcpy            \n",
            "      0.2          653,441          3     217,813.7    204,732.0   194,409      254,300       32,016.9  cudaFree              \n",
            "      0.1          264,055          1     264,055.0    264,055.0   264,055      264,055            0.0  cudaLaunchKernel      \n",
            "      0.0            2,429          1       2,429.0      2,429.0     2,429        2,429            0.0  cuModuleGetLoadingMode\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_gpu_kern_sum.py]... \n",
            "\n",
            " ** CUDA GPU Kernel Summary (cuda_gpu_kern_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)                                              Name                                             \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  ---------------------------------------------------------------------------------------------\n",
            "    100.0      160,054,287          1  160,054,287.0  160,054,287.0  160,054,287  160,054,287          0.0  void add_kernel_inner_loop<float>(T1 *, const T1 *, const T1 *, unsigned long, unsigned long)\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_gpu_mem_time_sum.py]... \n",
            "\n",
            " ** CUDA GPU MemOps Summary (by Time) (cuda_gpu_mem_time_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)      Operation     \n",
            " --------  ---------------  -----  ---------  ---------  --------  --------  -----------  ------------------\n",
            "     78.4        2,318,310      3  772,770.0  763,159.0   761,400   793,751     18,191.4  [CUDA memcpy HtoD]\n",
            "     21.6          640,473      1  640,473.0  640,473.0   640,473   640,473          0.0  [CUDA memcpy DtoH]\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_gpu_mem_size_sum.py]... \n",
            "\n",
            " ** CUDA GPU MemOps Summary (by Size) (cuda_gpu_mem_size_sum):\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ------------------\n",
            "     12.583      3     4.194     4.194     4.194     4.194        0.000  [CUDA memcpy HtoD]\n",
            "      4.194      1     4.194     4.194     4.194     4.194        0.000  [CUDA memcpy DtoH]\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/openmp_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain OpenMP event data.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/opengl_khr_range_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain KHR Extension (KHR_DEBUG) data.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/opengl_khr_gpu_range_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain GPU KHR Extension (KHR_DEBUG) data.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/vulkan_marker_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain Vulkan Debug Extension (Vulkan Debug Util) data.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/vulkan_gpu_marker_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain GPU Vulkan Debug Extension (GPU Vulkan Debug markers) data.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/dx11_pix_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain DX11 CPU debug markers.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/dx12_gpu_marker_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain DX12 GPU debug markers.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/dx12_pix_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain DX12 CPU debug markers.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/wddm_queue_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain WDDM context data.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/um_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain CUDA Unified Memory CPU page faults data.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/um_total_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain CUDA Unified Memory CPU page faults data.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/um_cpu_page_faults_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain CUDA Unified Memory CPU page faults data.\n",
            "\n",
            "Processing [add_cuda_profiling2.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/openacc_sum.py]... \n",
            "SKIPPED: add_cuda_profiling2.sqlite does not contain OpenACC event data.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA版本"
      ],
      "metadata": {
        "id": "6uemQC5MgjPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# CUDA版本\n",
        "nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JprapSp8glDL",
        "outputId": "27c3f98a-87ac-45e4-a0cf-67657b886519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Feb__7_19:32:13_PST_2023\n",
            "Cuda compilation tools, release 12.1, V12.1.66\n",
            "Build cuda_12.1.r12.1/compiler.32415258_0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%shell\n",
        "\n",
        "# 驱动支持的的最高版本，而非实际正在使用的版本！\n",
        "! nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZLvnOjqgr9k",
        "outputId": "6c32e8f4-8782-48df-d361-791eb8c36499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul 29 09:30:09 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}